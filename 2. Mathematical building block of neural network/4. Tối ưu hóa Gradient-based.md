Ở các phần trước, mỗi layer trong mạng neuron của model đều biến đổi các dữ liệu đầu vào dưới dạng:
	output = relu(dot(input, W) + b)
Trong đó, _W_ và _b_ là các tensor thuộc tính của lớp, còn gọi là _trọng số_ (weight) hoặc _tham số trainable_. Các trọng số này chứa dữ liệu đã học từ model.

Ban đầu, các ma trận trọng số chứa các giá trị nhỏ ngẫu nhiên (random initialization step).
Bước tiếp theo là điều chỉnh các trọng số này, dựa trên tín hiệu phản hồi (feedback signal),
sự điều chỉnh này gọi là _training_, thứ mà quá trình học máy hướng đến.

Quá trình training được lặp lại, gọi là _training loop_, bao gồm các bước:
1. Lấy một _batch_ (lô) dữ liệu mẫu - x, và các target tương ứng - y_true
2. Chạy model trên x (forward pass step) để đưa ra các dự đoán về y: y_pred
3. Tính toán loss của model trên batch (y_true <-> y_pred)
4. Cập nhật tất cả trọng số của model để làm giảm giá trị của loss trên batch
Sau khi trải qua các bước trên, mô hình học cách ánh xạ các đầu vào đến các mục tiêu chính xác, dẫn đến loss  rất thấp giữa y_pred và y_true.
Có một vấn đề ở bước 4 là với mỗi trọng số trong model, thì ta nên tăng hay giảm bao nhiêu?
Một giải pháp đơn giản là đóng băng tất cả các trọng số trong mô hình ngoại trừ một hệ số vô hướng đang được xem xét, và thử các giá trị khác nhau cho hệ số này. Giả sử giá trị ban đầu của hệ số là 0,3. Sau khi thực hiện bước tiến truyền trên một lô dữ liệu, loss của model trên lô dữ liệu là 0,5. Nếu bạn thay đổi giá trị của hệ số thành 0,35 và thực hiện lại bước forward pass, loss tăng lên 0,6. Nhưng nếu bạn giảm hệ số xuống 0,25, loss giảm xuống 0,4. Trong trường hợp này, có vẻ như việc cập nhật hệ số bằng -0,05 sẽ giúp giảm thiểu tổn thất. Quy trình này sẽ phải lặp lại cho tất cả các hệ số trong model.
Nhưng giải pháp trên rất kém hiệu quả, thay vào đó ta sẽ sử dụng <span style="color:rgb(66, 255, 242)">gradient descent</span>.
#### <span style="color:rgb(66, 255, 242)">Gradient descent</span>
Gradient descent là kỹ thuật tối ưu hóa được sử dụng rộng rãi trong các mạng neural hiện đại. Ý tưởng cơ bản của gradient descent là <span style="color:rgb(66, 255, 242)">sử dụng đạo hàm của loss function để điều chỉnh các trọng số của mô hình theo hướng làm giảm loss value</span>. Bằng cách này, mô hình có thể được điều chỉnh tự động dựa trên dữ liệu huấn luyện để cải thiện hiệu suất dự đoán. Quá trình này giúp mô hình học được cách biến đổi dữ liệu đầu vào thành các dự đoán chính xác hơn theo từng bước nhỏ.

### 1.Đạo hàm là gì (skip)

### <span style="color:rgb(0, 176, 240)">2. Đạo hàm của một tensor: gradient</span> 

### <span style="color:rgb(0, 176, 240)">3. Stochastic gradient descent - SGD</span>
Trong lý thuyết, với một hàm có đạo hàm, ta có thể tìm được giá trị nhỏ nhất của nó bằng tích phân.
Áp dụng vào mạng neural, điều này có nghĩa là tìm các giá trị trọng số mà mang lại hàm mất mát nhỏ nhất có thể. Việc này có thể được thực hiện bằng cách giải phương trình:
```lua
grad(f(W), W) = 0 
```
Đây là một phương trình đa thức của N biến, với N là số lượng hệ số trong mô hình. Mặc dù có thể giải phương trình này với N = 2 hoặc N = 3, nhưng làm như vậy là không khả thi đối với các mạng neural trong thực tế, vì số lượng tham số có thể lên đến hàng triệu.
Thay vào đó, ta có thể sử dụng thuật toán 4 bước được nêu ở trên nhưng có một chút thay đổi:
1. Lấy một _batch_ (lô) dữ liệu mẫu - x, và các target tương ứng - y_true
2. Chạy model trên x (forward pass step) để đưa ra các dự đoán về y: y_pred
3. Tính toán loss của model trên batch (y_true <-> y_pred)
4. Tính gradient của loss value theo các tham số của model (backward pass step)
5. Điều chỉnh tham số 1 chút theo hướng ngược lại với gradient, ví dụ:
	```lua
	W = W - <learning_rate> * gradient
	# learning_rate là một hệ số vô hướng điều chỉnh speed của gradient
```
	từ đó giảm được loss value trên batch.
![[Pasted image 20240709163519.png]]
Quy trình ở trên còn được gọi là <span style="color:rgb(66, 255, 242)">mini-batch SGD</span>. Thuật ngữ _stochastic_ đề cập đến việc rút ngẫu nhiên từ batch dữ liệu trong thực tế.Lưu ý rằng thuật toán trên chỉ lấy một mẫu duy nhất ở mỗi lần lặp thay vì lấy toàn bộ mẫu, và mỗi lần cập nhật sẽ chính xác hơn nhưng lại tốn rất nhiều.

Trong thực tế, gradient descent được áp dụng trên không gian có số chiều cao (ví dụ: hàng ngàn hoặc hàng triệu trọng số của mạng neural). Việc hiểu bề mặt loss có thể được trực quan hóa trên không gian 2 chiều (hình 2.19)
![[Pasted image 20240709163613.png]]nhưng không thể biểu diễn được không gian 1000000 chiều một cách hợp lý với con người. Do đó, các hiểu biết dựa trên biểu diễn thấp chiều này có thể không phản ánh đầy đủ thực tế trong việc training neural network.
Ngoài ra, còn tồn tại nhiều biến thể của SGD khác nhau dựa trên việc tính toán cập nhật trọng số tiếp theo bằng cách xem xét các cập nhật trọng số trước đó thay vì chỉ nhìn vào giá trị hiện tại của gradient. Ví dụ như SGD với momentum, cùng với Adagrad, RMSprop và một số phương pháp khác. Các biến thể này được biết đến như là các phương pháp tối ưu hóa hoặc tối ưu hóa (optimizer). Đặc biệt, khái niệm về momentum, được sử dụng trong nhiều biến thể này, đáng được quan tâm. Momentum giải quyết hai vấn đề của SGD: tốc độ hội tụ và các điểm cực tiểu cục bộ. ![[Pasted image 20240709164046.png]]
Xung quanh một giá trị tham số nhất định, có một điểm cực tiểu cục bộ: xung quanh điểm đó, di chuyển sang trái sẽ làm tăng mất mát, nhưng di chuyển sang phải cũng sẽ làm tăng mất mát. Nếu tham số đang được tối ưu hóa thông qua SGD với một tốc độ học nhỏ, quá trình tối ưu hóa có thể bị mắc kẹt tại điểm cực tiểu cục bộ thay vì tiến tới cực tiểu toàn cục.

Vấn đề này có thể tránh được bằng cách sử dụng momentum. Ví dụ trực quan ở đây là hình dung quá trình tối ưu hóa như một quả bóng nhỏ lăn xuống đường cong loss. Nếu có đủ đà, quả bóng sẽ không bị mắc kẹt trong hẻm núi và sẽ đến được cực tiểu toàn cục. Momentum được thực hiện bằng cách di chuyển quả bóng tại mỗi bước dựa không chỉ vào giá trị độ dốc hiện tại (gia tốc hiện tại) mà còn vào vận tốc hiện tại (kết quả từ gia tốc trong quá khứ). Trong thực tế, điều này có nghĩa là cập nhật tham số `w` không chỉ dựa vào giá trị gradient hiện tại mà còn vào cập nhật tham số trước đó, ví dụ như cài đặt đơn giản sau:
```python
past_velocity = 0
momentum = 0.1 // momentum không đổi
while loss> 0.01: // vòng lặp để tối ưu loss
	w, loss, gradient = get_current_parameter()
	velocity = past_velocity*momentum - learning_rate*gradient
	w = w + momentum * velocity - learning_rate*gradient
	past_velocity = velocity
	update_parameter(w)
```

### <span style="color:rgb(0, 176, 240)">4. Chaining derivative:</span> [Thuật toán lan truyền ngược ](obsidian://open?vault=deep%20learning&file=1.%20What%20is%20deep%20learning%2FCh%C3%BA%20th%C3%ADch%2FBackpropagation)
Vấn đề: 
- Làm thế nào để tính toán gradient của các biểu thức phức tạp trong thực tế?
- Làm thế nào để tính gradient của hàm mất mát theo trọng số?
Phương pháp: [Backpropagation](obsidian://open?vault=deep%20learning&file=1.%20What%20is%20deep%20learning%2FCh%C3%BA%20th%C3%ADch%2FBackpropagation)
Một mạng neural bao gồm nhiều phép toán tensor được liên kết với nhau, mỗi phép toán này có đạo hàm đơn giản và đã biết trước. Ví dụ, các model được định nghĩa ở [2.2](obsidian://open?vault=deep%20learning&file=2.%20Mathematical%20building%20block%20of%20neural%20network%2F2.Data%20representations%20for%20neural%20network) có thể được biểu diễn dưới dạng một hàm tham số hóa bởi các biến W1, b1, W2 và b2 (thuộc về lớp Dense thứ nhất và thứ hai tương ứng), bao gồm các phép toán như dot (nhân ma trận), relu (hàm kích hoạt ReLU), softmax và + (cộng hai tensor), cũng như hàm mất mát loss của chúng ta, tất cả đều có thể dễ dàng khả vi:
```lua
loss_value = loss(y_true, softmax(dot(relu(inputs,W1)+b1),W2)+b2)
```
Một chuỗi hàm như trên có thể được suy ra bằng cách sử dụng các đẳng thức gọi là <span style="color:rgb(66, 255, 242)">quy tắc chuỗi</span> - _chain rule_:
Xét hai hàm `f`, `g` và `fg` sao cho `fg(x)` = `f(g(x))`:
```python
def fg(x):
	x1 = g(x)
	y = f(x1)
	return y
```
Khi đó, quy tắc chuỗi nêu rõ `grad(y, x)` = `grad(y, x1)` * `grad(x1, x)`. Từ đó cho phép ta tính đạo hàm của `fg` khi biết được đạo hàm của `f` và `g`.
Quy tắc chuỗi được gọi là quy tắc chuỗi vì khi thêm vào các hàm trung gian thì nó bắt đầu giống với chuỗi:
```python
def fghj(x): 
	x1 = j(x) 
	x2 = h(x1) 
	x3 = g(x2) 
	y = f(x3) 
	return y
```
```lua 
grad(y, x) == (grad(y, x3) * grad(x3, x2) * grad(x2, x1) * grad(x1, x))
```

Áp dụng quy tắc chuỗi để tính toán các giá trị gradient của mạng neuron sẽ tạo ra thuật toán lan truyền ngược (backpropagation algorithm).

#### <span style="color:rgb(66, 255, 242)">Tự động vi phân với computational graph</span> 
Backpropagation có thể được hiểu thông qua đồ thị tính toán cấu trúc dữ liệu trung tâm của TensorFlow và các công nghệ học sâu.
![[Pasted image 20240710001451.png]]
Đồ thị tính toán là một đồ thị có hướng không có chu trình của các phép toán tensor. Đồ thị này cho phép mã hóa các biểu thức tính toán thành cấu trúc dữ liệu có thể đọc được bởi máy, giúp việc phân phối tính toán hoặc tự động tính toán đạo hàm dễ dàng hơn. Việc biểu diễn tính toán dưới dạng đồ thị rõ ràng giúp tăng tính linh hoạt và khả năng mở rộng, so với việc sử dụng mã ASCII truyền thống trong các tập tin như .py.

Để giải thích backpropagation, chúng ta xem xét một ví dụ cơ bản về đồ thị tính toán với một lớp tuyến tính và các biến vô hướng `w`, `b`, và `x`.
![[Pasted image 20240710002311.png]]
Kết hợp chúng tạo thành đầu ra `y`, sau đó áp dụng hàm mất mát giá trị tuyệt đối:
$$
loss val=∣y_{true}​−y∣
$$
Mục tiêu là cập nhật `w` và `b` để giảm thiểu `loss_val` bằng cách tính toán `grad(loss_val, b)` và `grad(loss_val, w)`.

Giả sử các giá trị cụ thể như sau:
```lua
x = 2
y_true = 4
w = 3
b = 1
```
Thu được quá trình truyền tiến (forward pass):
1. **Tính \( y \)**:
$$
   y=wx+b=3⋅2+1=6+1=7
$$
2. **Tính ( loss_val)**:
$$
  loss\_val=∣y_{true}​−y∣=∣4−7∣=∣−3∣=3
$$
![[Pasted image 20240710004248.png]]
Như vậy, quá trình truyền tiến giúp chúng ta tính toán giá trị mất mát từ các giá trị đầu vào và các tham số mô hình.

Đảo ngược đồ thị: đối với mỗi cạnh trong đồ thị đi từ A đến B, chúng ta sẽ tạo một cạnh ngược từ B đến A và liệu rằng, B thay đổi bao nhiêu khi A thay đổi? Nói cách khác, grad(B, A) là gì? Chúng ta sẽ chú thích mỗi cạnh đảo ngược với giá trị này. Đồ thị ngược này đại diện cho quá trình truyền ngược (backward pass).
![[Pasted image 20240710004558.png]]
Chúng ta có các giá trị gradient sau:$$
 grad(loss\_val,x2)=1
$$bởi vì khi x2 thay đổi một lượng `ϵ`, $loss\_val = ∣ 4−x2 ​∣$ thay đổi cùng một lượng.

$$
grad(x2,x1)=1
$$bởi vì khi x1x_1x1​ thay đổi một lượng `ϵ`, $x2 = x1+b = x1+1$ thay đổi cùng một lượng.

$$
grad(x2,b)=1
$$
bởi vì khi `b` thay đổi một lượng `ϵ`, $x2 = x1+b = 6+b$ thay đổi cùng một lượng.

$$
grad(x1,w)=2
$$
bởi vì khi `w` thay đổi một lượng `ϵ`, $x1=x⋅w=2⋅wx_1 = x ⋅w = 2$ thay đổi bởi $2⋅ϵ$

Quy tắc chuỗi cho phép tính đạo hàm của một node tới một node khác bằng cách nhân các đạo hàm cho mỗi cạnh dọc theo đường nối hai node đó. Ví dụ:
$$
grad(loss\_val,w)=grad(loss\_val,x2​)×grad(x2​,x1​)×grad(x1​,w)
$$
Sử dụng các giá trị gradient đã tính toán:
- $grad(loss_val,x2)=1$
- $grad(x2,x1)=1$
- $grad(x1,w)=2$
Chúng ta có:
$$
grad(loss\_val,w)=1×1×2=2
$$
Tổng quan:
- **Backpropagation** là việc áp dụng **chain rule** cho đồ thị tính toán.
- Quá trình này bắt đầu từ giá trị _loss_ cuối cùng và tính toán ngược lại để tìm ra gradient của từng tham số trong mô hình.
- Nhờ các framework hiện đại như TensorFlow với khả năng tự động tính toán đạo hàm, ta không cần phải viết các gradient bằng tay.

