### <span style="color:rgb(0, 176, 240)">1.Probabilistic modeling</span> 
Mô hình xác suất áp dụng nguyên tắc thống kê vào phân tích dữ liệu, là một trong những hình thức học máy sớm nhất và vẫn được sử dụng rộng rãi. Thuật toán nổi tiếng trong lĩnh vực này là <span style="color:rgb(66, 255, 242)">Naive Bayes, dựa trên định lý Bayes</span> và giả định các đặc trưng đầu vào độc lập. <span style="color:rgb(66, 255, 242)">Hồi quy logistic</span> (logistic regression - logreg), cũng là một <span style="color:rgb(66, 255, 242)">thuật toán phân loại quan trọng</span>, dù tên gọi gây hiểu nhầm là hồi quy. Cả Naive Bayes và logreg đều có từ trước khi máy tính ra đời và vẫn hữu ích nhờ tính đơn giản và linh hoạt.
### <span style="color:rgb(0, 176, 240)">2. Early neural network</span>
Các phiên bản đầu tiên của mạng neuron đã được thay thế bởi các biến thể hiện đại, nhưng việc hiểu nguồn gốc của học sâu vẫn có ích. Mặc dù các ý tưởng cốt lõi đã được nghiên cứu từ những năm 1950, phải đến giữa những năm 1980, khi thuật toán [[Backpropagation]] được tái khám phá và áp dụng, việc huấn luyện các mạng neural lớn mới trở nên khả thi. Ứng dụng thực tế thành công đầu tiên của mạng neural đến từ Bell Labs năm 1989, khi Yann LeCun kết hợp mạng neural tích chập và backpropagation để phân loại chữ số viết tay, tạo ra LeNet, được Dịch vụ Bưu chính Hoa Kỳ(United States Postal Service) sử dụng để đọc mã ZIP trên phong bì thư trong những năm 1990.
### <span style="color:rgb(0, 176, 240)">3. Kernel method</span>
### <span style="color:rgb(0, 176, 240)">4.Decision tree, random forest, gradient boosting machine</span>

